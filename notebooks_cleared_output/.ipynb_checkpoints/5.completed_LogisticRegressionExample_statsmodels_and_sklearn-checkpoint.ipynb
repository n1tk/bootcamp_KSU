{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to complete example using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "import seaborn as sns\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the version of the packages\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Matplotlib version ' + matplotlib.__version__)\n",
    "print('Numpy version ' + np.__version__)\n",
    "print('Seaborn version ' + sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = \"https://raw.githubusercontent.com/sb0709/bootcamp_KSU/master/Data/data.csv\"\n",
    "data = pd.read_csv(url_data,sep=',' ) # for specify the index we use here the colums \"0\" when reading the data: , index_col=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the order number column\n",
    "\n",
    "data = data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Lets make the 'MATCHKEY' as index for our analysis\n",
    "data.set_index('MATCHKEY', inplace=True) # inplace is to do replace int he currect dataframe, we can also assign the data to a new dataframe with the transofmations.\n",
    "\n",
    "\n",
    "data['goodbad'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 'goodbad' column\n",
    "# https://seaborn.pydata.org/generated/seaborn.countplot.html\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"goodbad\", data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\n",
    "\n",
    "# Here we move on to take a look of the mean/average of the data accros the 2 classes for the 'goodbad'\n",
    "\n",
    "# Note: we can calculate the average accros other categorical variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.groupby('goodbad').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean/average of the data accros the classes for the 'AGE_groups'\n",
    "\n",
    "data.groupby('AGE_groups').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.AGE_groups,data.goodbad).plot(kind='bar')\n",
    "plt.title('goodbad frequency for Age_groups')\n",
    "plt.xlabel('AGE_groups')\n",
    "plt.ylabel('Frequency of AGE_groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for modeling will use Feature ranking with recursive feature elimination. \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "# works as follow: Construct repeatedly a model and takes features each by one and test with the remaining and set aside till all the features \n",
    "# are used and selects the best performing model by using the the minimum for the best performing model.\n",
    "\n",
    "# Example here:\n",
    "\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, 5, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "print(\"Print The mask of selected features: \", selector.support_)\n",
    "print()\n",
    "\n",
    "print(\"Print The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.\", selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split in X and Y\n",
    "\n",
    "# for drop the index: df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# df = data.reset_index(drop = True, inplace = True)\n",
    "#print(df.head())\n",
    "\n",
    "X = data.drop(['goodbad','AGE_groups'], axis=1)\n",
    "print('Matrix Shape of X is:', X.shape, X.head())\n",
    "\n",
    "y = data['goodbad']\n",
    "print('Target variable shape \"y\" is:', y.shape, y.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"AGE_groups\"] = X[\"AGE_groups\"].astype('category')\n",
    "\n",
    "#check the column names:\n",
    "\n",
    "X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for all 7 variables\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "selector = RFE(logreg, 7, step=1) #7 is n_features_to_select, default is none and is is none than is used half of the features.\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "print(\"Print The mask of selected features: \", selector.support_)\n",
    "print()\n",
    "\n",
    "print(\"Print The feature ranking:\", selector.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to have 5 variables selected finally than we have the following: \n",
    "\n",
    "selector = RFE(logreg, 5, step=1) #5 is n_features_to_select, default is none and is is none than is used half of the features.\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "print(\"Print The mask of selected features: \", selector.support_)\n",
    "print()\n",
    "\n",
    "print(\"Print The feature ranking:\", selector.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the logistic model  using statsmodel package:\n",
    "\n",
    "\n",
    "`statsmodels` is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. An extensive list of result statistics are available for each estimator. \n",
    "The results are tested against existing statistical packages to ensure that they are correct. \n",
    "The package is released under the open source Modified BSD (3-clause) license. The online documentation is hosted at statsmodels.org.\n",
    "\n",
    "\n",
    "https://www.statsmodels.org/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit_model=sm.Logit(y,X) # create the model\n",
    "\n",
    "result=logit_model.fit() # fit the model\n",
    "\n",
    "print(result.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation/Summary : p-value for most of our selected variables are significant except BRAGE and BRNEW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now example using sklearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write the data to the disk macOS location github\n",
    "###### data.to_csv('/Users/sb0709/Documents/GitHub/bootcamp_KSU/Data/data_reg.csv', sep = ',')\n",
    "\n",
    "# pushing all datasets to github for reading csv for this tutorials\n",
    "##### data.to_csv('/home/sb0709/github_repos/bootcamp_KSU/Data/data_reg.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified original http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html#sphx-glr-auto-examples-linear-model-plot-iris-logistic-py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# import some data to play with\n",
    "X = data.drop(['goodbad','AGE_groups'], axis=1)\n",
    "print('Matrix Shape of X is:', X.shape, X.head())\n",
    "\n",
    "y = data['goodbad'] # target variable\n",
    "print('Target variable shape \"y\" is:', y.shape, y.head())\n",
    "\n",
    "#split/create the dataset in train and test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg = LogisticRegression() #logisticRegression\n",
    "print(logreg.fit(X_train, y_train))\n",
    "\n",
    "# Clustering\n",
    "\n",
    "knn = KNeighborsClassifier() #clustering\n",
    "print(knn.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LogisticRegression score: %f'\n",
    "      % logreg.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of Logistic Regression classifier on test dataset:', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: correct predictions are: 236 + 2, incorect predictions are:  7 + 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a text report showing the main classification metrics\n",
    "\n",
    "\n",
    "\n",
    "``` python\n",
    "klearn.metrics.classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36(bootcampDS)",
   "language": "python",
   "name": "bootcamp_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
